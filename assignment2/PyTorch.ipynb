{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a ConvNet PyTorch\n",
    "\n",
    "In this notebook, you'll learn how to use the powerful PyTorch framework to specify a conv net architecture and train it on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's this PyTorch business?\n",
    "\n",
    "You've written a lot of code in this assignment to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. You've also worked hard to make your code efficient and vectorized.\n",
    "\n",
    "For the last part of this assignment, though, we're going to leave behind your beautiful codebase and instead migrate to one of two popular deep learning frameworks: in this instance, PyTorch (or TensorFlow, if you switch over to that notebook). \n",
    "\n",
    "Why?\n",
    "\n",
    "* Our code will now run on GPUs! Much faster training. When using a framework like PyTorch or TensorFlow you can harness the power of the GPU for your own custom neural network architectures without having to write CUDA code directly (which is beyond the scope of this class).\n",
    "* We want you to be ready to use one of these frameworks for your project so you can experiment more efficiently than if you were writing every feature you want to use by hand. \n",
    "* We want you to stand on the shoulders of giants! TensorFlow and PyTorch are both excellent frameworks that will make your lives a lot easier, and now that you understand their guts, you are free to use them :) \n",
    "* We want you to be exposed to the sort of deep learning code you might run into in academia or industry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How will I learn PyTorch?\n",
    "\n",
    "If you've used Torch before, but are new to PyTorch, this tutorial might be of use: http://pytorch.org/tutorials/beginner/former_torchies_tutorial.html\n",
    "\n",
    "Otherwise, this notebook will walk you through much of what you need to do to train models in Torch. See the end of the notebook for some links to helpful tutorials if you want to learn more or need further clarification on topics that aren't fully explained here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "\n",
    "We load the CIFAR-10 dataset. This might take a couple minutes the first time you do it, but the files should stay cached after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True,\n",
    "                          transform=T.ToTensor())\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we're going to use a CPU-friendly datatype. Later, we'll switch to a datatype that will move all our computations to the GPU and measure the speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor # the CPU datatype\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "# This is a little utility that we'll use to reset the model\n",
    "# if we want to re-initialize all our parameters\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Model\n",
    "\n",
    "### Some assorted tidbits\n",
    "\n",
    "Let's start by looking at a simple model. First, note that PyTorch operates on Tensors, which are n-dimensional arrays functionally analogous to numpy's ndarrays, with the additional feature that they can be used for computations on GPUs.\n",
    "\n",
    "We'll provide you with a Flatten function, which we explain here. Remember that our image data (and more relevantly, our intermediate feature maps) are initially N x C x H x W, where:\n",
    "* N is the number of datapoints\n",
    "* C is the number of channels\n",
    "* H is the height of the intermediate feature map in pixels\n",
    "* W is the height of the intermediate feature map in pixels\n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, that needs spatial understanding of where the intermediate features are relative to each other. When we input  data into fully connected affine layers, however, we want each datapoint to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data. So, we use a \"Flatten\" operation to collapse the C x H x W values per representation into a single long vector. The Flatten function below first reads in the N, C, H, and W values from a given batch of data, and then returns a \"view\" of that data. \"View\" is analogous to numpy's \"reshape\" method: it reshapes x's dimensions to be N x ??, where ?? is allowed to be anything (in this case, it will be C x H x W, but we don't need to specify that explicitly). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The example model itself\n",
    "\n",
    "The first step to training your own model is defining its architecture.\n",
    "\n",
    "Here's an example of a convolutional neural network defined in PyTorch -- try to understand what each line is doing, remembering that each layer is composed upon the previous layer. We haven't trained anything yet - that'll come next - for now, we want you to understand how everything gets set up.  nn.Sequential is a container which applies each layer\n",
    "one after the other.\n",
    "\n",
    "In that example, you see 2D convolutional layers (Conv2d), ReLU activations, and fully-connected layers (Linear). You also see the Cross-Entropy loss function, and the Adam optimizer being used. \n",
    "\n",
    "Make sure you understand why the parameters of the Linear layer are 5408 and 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's where we define the architecture of the model... \n",
    "simple_model = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=7, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                Flatten(), # see above for explanation\n",
    "                nn.Linear(5408, 10), # affine layer\n",
    "              )\n",
    "\n",
    "# Set the type of all data in this model to be FloatTensor \n",
    "simple_model.type(dtype)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.Adam(simple_model.parameters(), lr=1e-2) # lr sets the learning rate of the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch supports many other layer types, loss functions, and optimizers - you will experiment with these next. Here's the official API documentation for these (if any of the parameters used above were unclear, this resource will also be helpful). One note: what we call in the class \"spatial batch norm\" is called \"BatchNorm2D\" in PyTorch.\n",
    "\n",
    "* Layers: http://pytorch.org/docs/nn.html\n",
    "* Activations: http://pytorch.org/docs/nn.html#non-linear-activations\n",
    "* Loss functions: http://pytorch.org/docs/nn.html#loss-functions\n",
    "* Optimizers: http://pytorch.org/docs/optim.html#algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a specific model\n",
    "\n",
    "In this section, we're going to specify a model for you to construct. The goal here isn't to get good performance (that'll be next), but instead to get comfortable with understanding the PyTorch documentation and configuring your own model. \n",
    "\n",
    "Using the code provided above as guidance, and using the following PyTorch documentation, specify a model with the following architecture:\n",
    "\n",
    "* 7x7 Convolutional Layer with 32 filters and stride of 1\n",
    "* ReLU Activation Layer\n",
    "* Spatial Batch Normalization Layer\n",
    "* 2x2 Max Pooling layer with a stride of 2\n",
    "* Affine layer with 1024 output units\n",
    "* ReLU Activation Layer\n",
    "* Affine layer from 1024 input units to 10 outputs\n",
    "\n",
    "And finally, set up a **cross-entropy** loss function and the **RMSprop** learning rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_model_base = nn.Sequential( # You fill this in!\n",
    "                nn.Conv2d(3, 32, kernel_size=7, stride=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(32, affine=False),\n",
    "                nn.MaxPool2d(2, stride=2),\n",
    "                Flatten(), # see above for explanation\n",
    "                nn.Linear(5408, 1024), # affine layer\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(1024, 10)\n",
    "            )\n",
    "fixed_model = fixed_model_base.type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you're doing the right thing, use the following tool to check the dimensionality of your output (it should be 64 x 10, since our batches have size 64 and the output of the final affine layer should be 10, corresponding to our 10 classes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
    "x = torch.randn(64, 3, 32, 32).type(dtype)\n",
    "x_var = Variable(x.type(dtype)) # Construct a PyTorch Variable out of your input data\n",
    "ans = fixed_model(x_var)        # Feed it through the model! \n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, 10]))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU!\n",
    "\n",
    "Now, we're going to switch the dtype of the model and our data to the GPU-friendly tensors, and see what happens... everything is the same, except we are casting our model and input tensors as this new dtype instead of the old one.\n",
    "\n",
    "If this returns false, or otherwise fails in a not-graceful way (i.e., with some error message), you may not have an NVIDIA GPU available on your machine. If you're running locally, we recommend you switch to Google Cloud and follow the instructions to set up a GPU there. If you're already on Google Cloud, something is wrong -- make sure you followed the instructions on how to request and use a GPU on your instance. If you did, post on Piazza or come to Office Hours so we can help you debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that CUDA is properly configured and you have a GPU available\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "fixed_model_gpu = copy.deepcopy(fixed_model_base).type(gpu_dtype)\n",
    "\n",
    "x_gpu = torch.randn(64, 3, 32, 32).type(gpu_dtype)\n",
    "x_var_gpu = Variable(x.type(gpu_dtype)) # Construct a PyTorch Variable out of your input data\n",
    "ans = fixed_model_gpu(x_var_gpu)        # Feed it through the model! \n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to evaluate the performance of the forward pass running on the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.9 ms ± 4.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "ans = fixed_model(x_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and now the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.59 ms ± 152 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "torch.cuda.synchronize() # Make sure there are no pending GPU computations\n",
    "ans = fixed_model_gpu(x_var_gpu)        # Feed it through the model! \n",
    "torch.cuda.synchronize() # Make sure there are no pending GPU computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe that even a simple forward pass like this is significantly faster on the GPU. So for the rest of the assignment (and when you go train your models in assignment 3 and your project!), you should use the GPU datatype for your model and your tensors: as a reminder that is *torch.cuda.FloatTensor* (in our notebook here as *gpu_dtype*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model.\n",
    "\n",
    "Now that you've seen how to define a model and do a single forward pass of some data through it, let's  walk through how you'd actually train one whole epoch over your training data (using the simple_model we provided above).\n",
    "\n",
    "Make sure you understand how each PyTorch function used below corresponds to what you implemented in your custom neural network implementation.\n",
    "\n",
    "Note that because we are not resetting the weights anywhere below, if you run the cell multiple times, you are effectively training multiple epochs (so your performance should improve).\n",
    "\n",
    "First, set up an RMSprop optimizer (using a 1e-3 learning rate) and a cross-entropy loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_fn = None\n",
    "optimizer = None\n",
    "pass\n",
    "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(fixed_model_gpu.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "t = 100, loss = 1.3819\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "t = 200, loss = 1.5596\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "t = 300, loss = 1.4347\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "t = 400, loss = 1.3912\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "t = 500, loss = 1.2718\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "t = 600, loss = 1.3220\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "t = 700, loss = 1.4913\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([40, 10])\n"
     ]
    }
   ],
   "source": [
    "# This sets the model in \"training\" mode. This is relevant for some layers that may have different behavior\n",
    "# in training mode vs testing mode, such as Dropout and BatchNorm. \n",
    "fixed_model_gpu.train()\n",
    "\n",
    "# Load one batch at a time.\n",
    "for t, (x, y) in enumerate(loader_train):\n",
    "    x_var = Variable(x.type(gpu_dtype))\n",
    "    y_var = Variable(y.type(gpu_dtype).long())\n",
    "\n",
    "    # This is the forward pass: predict the scores for each class, for each x in the batch.\n",
    "    scores = fixed_model_gpu(x_var)\n",
    "    print(scores.size())\n",
    "    # Use the correct y values and the predicted y values to compute the loss.\n",
    "    loss = loss_fn(scores, y_var)\n",
    "    \n",
    "    if (t + 1) % print_every == 0:\n",
    "        print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "\n",
    "    # Zero out all of the gradients for the variables which the optimizer will update.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # This is the backwards pass: compute the gradient of the loss with respect to each \n",
    "    # parameter of the model.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Actually update the parameters of the model using the gradients computed by the backwards pass.\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've seen how the training process works in PyTorch. To save you writing boilerplate code, we're providing the following helper functions to help you train for multiple epochs and check the accuracy of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.type(gpu_dtype))\n",
    "            y_var = Variable(y.type(gpu_dtype).long())\n",
    "            scores = model(x_var)\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def check_accuracy(model, loader):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in loader:\n",
    "        x_var = Variable(x.type(gpu_dtype), volatile=True)\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the accuracy of the model.\n",
    "\n",
    "Let's see the train and check_accuracy code in action -- feel free to use these methods when evaluating the models you develop below.\n",
    "\n",
    "You should get a training loss of around 1.2-1.4, and a validation accuracy of around 50-60%. As mentioned above, if you re-run the cells, you'll be training more epochs, so your performance will improve past these numbers.\n",
    "\n",
    "But don't worry about getting these numbers better -- this was just practice before you tackle designing your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "0 torch.Size([64, 3, 32, 32])\n",
      "1 torch.Size([64, 3, 32, 32])\n",
      "2 torch.Size([64, 3, 32, 32])\n",
      "3 torch.Size([64, 3, 32, 32])\n",
      "4 torch.Size([64, 3, 32, 32])\n",
      "5 torch.Size([64, 3, 32, 32])\n",
      "6 torch.Size([64, 3, 32, 32])\n",
      "7 torch.Size([64, 3, 32, 32])\n",
      "8 torch.Size([64, 3, 32, 32])\n",
      "9 torch.Size([64, 3, 32, 32])\n",
      "10 torch.Size([64, 3, 32, 32])\n",
      "11 torch.Size([64, 3, 32, 32])\n",
      "12 torch.Size([64, 3, 32, 32])\n",
      "13 torch.Size([64, 3, 32, 32])\n",
      "14 torch.Size([64, 3, 32, 32])\n",
      "15 torch.Size([64, 3, 32, 32])\n",
      "16 torch.Size([64, 3, 32, 32])\n",
      "17 torch.Size([64, 3, 32, 32])\n",
      "18 torch.Size([64, 3, 32, 32])\n",
      "19 torch.Size([64, 3, 32, 32])\n",
      "20 torch.Size([64, 3, 32, 32])\n",
      "21 torch.Size([64, 3, 32, 32])\n",
      "22 torch.Size([64, 3, 32, 32])\n",
      "23 torch.Size([64, 3, 32, 32])\n",
      "24 torch.Size([64, 3, 32, 32])\n",
      "25 torch.Size([64, 3, 32, 32])\n",
      "26 torch.Size([64, 3, 32, 32])\n",
      "27 torch.Size([64, 3, 32, 32])\n",
      "28 torch.Size([64, 3, 32, 32])\n",
      "29 torch.Size([64, 3, 32, 32])\n",
      "30 torch.Size([64, 3, 32, 32])\n",
      "31 torch.Size([64, 3, 32, 32])\n",
      "32 torch.Size([64, 3, 32, 32])\n",
      "33 torch.Size([64, 3, 32, 32])\n",
      "34 torch.Size([64, 3, 32, 32])\n",
      "35 torch.Size([64, 3, 32, 32])\n",
      "36 torch.Size([64, 3, 32, 32])\n",
      "37 torch.Size([64, 3, 32, 32])\n",
      "38 torch.Size([64, 3, 32, 32])\n",
      "39 torch.Size([64, 3, 32, 32])\n",
      "40 torch.Size([64, 3, 32, 32])\n",
      "41 torch.Size([64, 3, 32, 32])\n",
      "42 torch.Size([64, 3, 32, 32])\n",
      "43 torch.Size([64, 3, 32, 32])\n",
      "44 torch.Size([64, 3, 32, 32])\n",
      "45 torch.Size([64, 3, 32, 32])\n",
      "46 torch.Size([64, 3, 32, 32])\n",
      "47 torch.Size([64, 3, 32, 32])\n",
      "48 torch.Size([64, 3, 32, 32])\n",
      "49 torch.Size([64, 3, 32, 32])\n",
      "50 torch.Size([64, 3, 32, 32])\n",
      "51 torch.Size([64, 3, 32, 32])\n",
      "52 torch.Size([64, 3, 32, 32])\n",
      "53 torch.Size([64, 3, 32, 32])\n",
      "54 torch.Size([64, 3, 32, 32])\n",
      "55 torch.Size([64, 3, 32, 32])\n",
      "56 torch.Size([64, 3, 32, 32])\n",
      "57 torch.Size([64, 3, 32, 32])\n",
      "58 torch.Size([64, 3, 32, 32])\n",
      "59 torch.Size([64, 3, 32, 32])\n",
      "60 torch.Size([64, 3, 32, 32])\n",
      "61 torch.Size([64, 3, 32, 32])\n",
      "62 torch.Size([64, 3, 32, 32])\n",
      "63 torch.Size([64, 3, 32, 32])\n",
      "64 torch.Size([64, 3, 32, 32])\n",
      "65 torch.Size([64, 3, 32, 32])\n",
      "66 torch.Size([64, 3, 32, 32])\n",
      "67 torch.Size([64, 3, 32, 32])\n",
      "68 torch.Size([64, 3, 32, 32])\n",
      "69 torch.Size([64, 3, 32, 32])\n",
      "70 torch.Size([64, 3, 32, 32])\n",
      "71 torch.Size([64, 3, 32, 32])\n",
      "72 torch.Size([64, 3, 32, 32])\n",
      "73 torch.Size([64, 3, 32, 32])\n",
      "74 torch.Size([64, 3, 32, 32])\n",
      "75 torch.Size([64, 3, 32, 32])\n",
      "76 torch.Size([64, 3, 32, 32])\n",
      "77 torch.Size([64, 3, 32, 32])\n",
      "78 torch.Size([64, 3, 32, 32])\n",
      "79 torch.Size([64, 3, 32, 32])\n",
      "80 torch.Size([64, 3, 32, 32])\n",
      "81 torch.Size([64, 3, 32, 32])\n",
      "82 torch.Size([64, 3, 32, 32])\n",
      "83 torch.Size([64, 3, 32, 32])\n",
      "84 torch.Size([64, 3, 32, 32])\n",
      "85 torch.Size([64, 3, 32, 32])\n",
      "86 torch.Size([64, 3, 32, 32])\n",
      "87 torch.Size([64, 3, 32, 32])\n",
      "88 torch.Size([64, 3, 32, 32])\n",
      "89 torch.Size([64, 3, 32, 32])\n",
      "90 torch.Size([64, 3, 32, 32])\n",
      "91 torch.Size([64, 3, 32, 32])\n",
      "92 torch.Size([64, 3, 32, 32])\n",
      "93 torch.Size([64, 3, 32, 32])\n",
      "94 torch.Size([64, 3, 32, 32])\n",
      "95 torch.Size([64, 3, 32, 32])\n",
      "96 torch.Size([64, 3, 32, 32])\n",
      "97 torch.Size([64, 3, 32, 32])\n",
      "98 torch.Size([64, 3, 32, 32])\n",
      "99 torch.Size([64, 3, 32, 32])\n",
      "t = 100, loss = 1.4068\n",
      "100 torch.Size([64, 3, 32, 32])\n",
      "101 torch.Size([64, 3, 32, 32])\n",
      "102 torch.Size([64, 3, 32, 32])\n",
      "103 torch.Size([64, 3, 32, 32])\n",
      "104 torch.Size([64, 3, 32, 32])\n",
      "105 torch.Size([64, 3, 32, 32])\n",
      "106 torch.Size([64, 3, 32, 32])\n",
      "107 torch.Size([64, 3, 32, 32])\n",
      "108 torch.Size([64, 3, 32, 32])\n",
      "109 torch.Size([64, 3, 32, 32])\n",
      "110 torch.Size([64, 3, 32, 32])\n",
      "111 torch.Size([64, 3, 32, 32])\n",
      "112 torch.Size([64, 3, 32, 32])\n",
      "113 torch.Size([64, 3, 32, 32])\n",
      "114 torch.Size([64, 3, 32, 32])\n",
      "115 torch.Size([64, 3, 32, 32])\n",
      "116 torch.Size([64, 3, 32, 32])\n",
      "117 torch.Size([64, 3, 32, 32])\n",
      "118 torch.Size([64, 3, 32, 32])\n",
      "119 torch.Size([64, 3, 32, 32])\n",
      "120 torch.Size([64, 3, 32, 32])\n",
      "121 torch.Size([64, 3, 32, 32])\n",
      "122 torch.Size([64, 3, 32, 32])\n",
      "123 torch.Size([64, 3, 32, 32])\n",
      "124 torch.Size([64, 3, 32, 32])\n",
      "125 torch.Size([64, 3, 32, 32])\n",
      "126 torch.Size([64, 3, 32, 32])\n",
      "127 torch.Size([64, 3, 32, 32])\n",
      "128 torch.Size([64, 3, 32, 32])\n",
      "129 torch.Size([64, 3, 32, 32])\n",
      "130 torch.Size([64, 3, 32, 32])\n",
      "131 torch.Size([64, 3, 32, 32])\n",
      "132 torch.Size([64, 3, 32, 32])\n",
      "133 torch.Size([64, 3, 32, 32])\n",
      "134 torch.Size([64, 3, 32, 32])\n",
      "135 torch.Size([64, 3, 32, 32])\n",
      "136 torch.Size([64, 3, 32, 32])\n",
      "137 torch.Size([64, 3, 32, 32])\n",
      "138 torch.Size([64, 3, 32, 32])\n",
      "139 torch.Size([64, 3, 32, 32])\n",
      "140 torch.Size([64, 3, 32, 32])\n",
      "141 torch.Size([64, 3, 32, 32])\n",
      "142 torch.Size([64, 3, 32, 32])\n",
      "143 torch.Size([64, 3, 32, 32])\n",
      "144 torch.Size([64, 3, 32, 32])\n",
      "145 torch.Size([64, 3, 32, 32])\n",
      "146 torch.Size([64, 3, 32, 32])\n",
      "147 torch.Size([64, 3, 32, 32])\n",
      "148 torch.Size([64, 3, 32, 32])\n",
      "149 torch.Size([64, 3, 32, 32])\n",
      "150 torch.Size([64, 3, 32, 32])\n",
      "151 torch.Size([64, 3, 32, 32])\n",
      "152 torch.Size([64, 3, 32, 32])\n",
      "153 torch.Size([64, 3, 32, 32])\n",
      "154 torch.Size([64, 3, 32, 32])\n",
      "155 torch.Size([64, 3, 32, 32])\n",
      "156 torch.Size([64, 3, 32, 32])\n",
      "157 torch.Size([64, 3, 32, 32])\n",
      "158 torch.Size([64, 3, 32, 32])\n",
      "159 torch.Size([64, 3, 32, 32])\n",
      "160 torch.Size([64, 3, 32, 32])\n",
      "161 torch.Size([64, 3, 32, 32])\n",
      "162 torch.Size([64, 3, 32, 32])\n",
      "163 torch.Size([64, 3, 32, 32])\n",
      "164 torch.Size([64, 3, 32, 32])\n",
      "165 torch.Size([64, 3, 32, 32])\n",
      "166 torch.Size([64, 3, 32, 32])\n",
      "167 torch.Size([64, 3, 32, 32])\n",
      "168 torch.Size([64, 3, 32, 32])\n",
      "169 torch.Size([64, 3, 32, 32])\n",
      "170 torch.Size([64, 3, 32, 32])\n",
      "171 torch.Size([64, 3, 32, 32])\n",
      "172 torch.Size([64, 3, 32, 32])\n",
      "173 torch.Size([64, 3, 32, 32])\n",
      "174 torch.Size([64, 3, 32, 32])\n",
      "175 torch.Size([64, 3, 32, 32])\n",
      "176 torch.Size([64, 3, 32, 32])\n",
      "177 torch.Size([64, 3, 32, 32])\n",
      "178 torch.Size([64, 3, 32, 32])\n",
      "179 torch.Size([64, 3, 32, 32])\n",
      "180 torch.Size([64, 3, 32, 32])\n",
      "181 torch.Size([64, 3, 32, 32])\n",
      "182 torch.Size([64, 3, 32, 32])\n",
      "183 torch.Size([64, 3, 32, 32])\n",
      "184 torch.Size([64, 3, 32, 32])\n",
      "185 torch.Size([64, 3, 32, 32])\n",
      "186 torch.Size([64, 3, 32, 32])\n",
      "187 torch.Size([64, 3, 32, 32])\n",
      "188 torch.Size([64, 3, 32, 32])\n",
      "189 torch.Size([64, 3, 32, 32])\n",
      "190 torch.Size([64, 3, 32, 32])\n",
      "191 torch.Size([64, 3, 32, 32])\n",
      "192 torch.Size([64, 3, 32, 32])\n",
      "193 torch.Size([64, 3, 32, 32])\n",
      "194 torch.Size([64, 3, 32, 32])\n",
      "195 torch.Size([64, 3, 32, 32])\n",
      "196 torch.Size([64, 3, 32, 32])\n",
      "197 torch.Size([64, 3, 32, 32])\n",
      "198 torch.Size([64, 3, 32, 32])\n",
      "199 torch.Size([64, 3, 32, 32])\n",
      "t = 200, loss = 1.5593\n",
      "200 torch.Size([64, 3, 32, 32])\n",
      "201 torch.Size([64, 3, 32, 32])\n",
      "202 torch.Size([64, 3, 32, 32])\n",
      "203 torch.Size([64, 3, 32, 32])\n",
      "204 torch.Size([64, 3, 32, 32])\n",
      "205 torch.Size([64, 3, 32, 32])\n",
      "206 torch.Size([64, 3, 32, 32])\n",
      "207 torch.Size([64, 3, 32, 32])\n",
      "208 torch.Size([64, 3, 32, 32])\n",
      "209 torch.Size([64, 3, 32, 32])\n",
      "210 torch.Size([64, 3, 32, 32])\n",
      "211 torch.Size([64, 3, 32, 32])\n",
      "212 torch.Size([64, 3, 32, 32])\n",
      "213 torch.Size([64, 3, 32, 32])\n",
      "214 torch.Size([64, 3, 32, 32])\n",
      "215 torch.Size([64, 3, 32, 32])\n",
      "216 torch.Size([64, 3, 32, 32])\n",
      "217 torch.Size([64, 3, 32, 32])\n",
      "218 torch.Size([64, 3, 32, 32])\n",
      "219 torch.Size([64, 3, 32, 32])\n",
      "220 torch.Size([64, 3, 32, 32])\n",
      "221 torch.Size([64, 3, 32, 32])\n",
      "222 torch.Size([64, 3, 32, 32])\n",
      "223 torch.Size([64, 3, 32, 32])\n",
      "224 torch.Size([64, 3, 32, 32])\n",
      "225 torch.Size([64, 3, 32, 32])\n",
      "226 torch.Size([64, 3, 32, 32])\n",
      "227 torch.Size([64, 3, 32, 32])\n",
      "228 torch.Size([64, 3, 32, 32])\n",
      "229 torch.Size([64, 3, 32, 32])\n",
      "230 torch.Size([64, 3, 32, 32])\n",
      "231 torch.Size([64, 3, 32, 32])\n",
      "232 torch.Size([64, 3, 32, 32])\n",
      "233 torch.Size([64, 3, 32, 32])\n",
      "234 torch.Size([64, 3, 32, 32])\n",
      "235 torch.Size([64, 3, 32, 32])\n",
      "236 torch.Size([64, 3, 32, 32])\n",
      "237 torch.Size([64, 3, 32, 32])\n",
      "238 torch.Size([64, 3, 32, 32])\n",
      "239 torch.Size([64, 3, 32, 32])\n",
      "240 torch.Size([64, 3, 32, 32])\n",
      "241 torch.Size([64, 3, 32, 32])\n",
      "242 torch.Size([64, 3, 32, 32])\n",
      "243 torch.Size([64, 3, 32, 32])\n",
      "244 torch.Size([64, 3, 32, 32])\n",
      "245 torch.Size([64, 3, 32, 32])\n",
      "246 torch.Size([64, 3, 32, 32])\n",
      "247 torch.Size([64, 3, 32, 32])\n",
      "248 torch.Size([64, 3, 32, 32])\n",
      "249 torch.Size([64, 3, 32, 32])\n",
      "250 torch.Size([64, 3, 32, 32])\n",
      "251 torch.Size([64, 3, 32, 32])\n",
      "252 torch.Size([64, 3, 32, 32])\n",
      "253 torch.Size([64, 3, 32, 32])\n",
      "254 torch.Size([64, 3, 32, 32])\n",
      "255 torch.Size([64, 3, 32, 32])\n",
      "256 torch.Size([64, 3, 32, 32])\n",
      "257 torch.Size([64, 3, 32, 32])\n",
      "258 torch.Size([64, 3, 32, 32])\n",
      "259 torch.Size([64, 3, 32, 32])\n",
      "260 torch.Size([64, 3, 32, 32])\n",
      "261 torch.Size([64, 3, 32, 32])\n",
      "262 torch.Size([64, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 torch.Size([64, 3, 32, 32])\n",
      "264 torch.Size([64, 3, 32, 32])\n",
      "265 torch.Size([64, 3, 32, 32])\n",
      "266 torch.Size([64, 3, 32, 32])\n",
      "267 torch.Size([64, 3, 32, 32])\n",
      "268 torch.Size([64, 3, 32, 32])\n",
      "269 torch.Size([64, 3, 32, 32])\n",
      "270 torch.Size([64, 3, 32, 32])\n",
      "271 torch.Size([64, 3, 32, 32])\n",
      "272 torch.Size([64, 3, 32, 32])\n",
      "273 torch.Size([64, 3, 32, 32])\n",
      "274 torch.Size([64, 3, 32, 32])\n",
      "275 torch.Size([64, 3, 32, 32])\n",
      "276 torch.Size([64, 3, 32, 32])\n",
      "277 torch.Size([64, 3, 32, 32])\n",
      "278 torch.Size([64, 3, 32, 32])\n",
      "279 torch.Size([64, 3, 32, 32])\n",
      "280 torch.Size([64, 3, 32, 32])\n",
      "281 torch.Size([64, 3, 32, 32])\n",
      "282 torch.Size([64, 3, 32, 32])\n",
      "283 torch.Size([64, 3, 32, 32])\n",
      "284 torch.Size([64, 3, 32, 32])\n",
      "285 torch.Size([64, 3, 32, 32])\n",
      "286 torch.Size([64, 3, 32, 32])\n",
      "287 torch.Size([64, 3, 32, 32])\n",
      "288 torch.Size([64, 3, 32, 32])\n",
      "289 torch.Size([64, 3, 32, 32])\n",
      "290 torch.Size([64, 3, 32, 32])\n",
      "291 torch.Size([64, 3, 32, 32])\n",
      "292 torch.Size([64, 3, 32, 32])\n",
      "293 torch.Size([64, 3, 32, 32])\n",
      "294 torch.Size([64, 3, 32, 32])\n",
      "295 torch.Size([64, 3, 32, 32])\n",
      "296 torch.Size([64, 3, 32, 32])\n",
      "297 torch.Size([64, 3, 32, 32])\n",
      "298 torch.Size([64, 3, 32, 32])\n",
      "299 torch.Size([64, 3, 32, 32])\n",
      "t = 300, loss = 1.3473\n",
      "300 torch.Size([64, 3, 32, 32])\n",
      "301 torch.Size([64, 3, 32, 32])\n",
      "302 torch.Size([64, 3, 32, 32])\n",
      "303 torch.Size([64, 3, 32, 32])\n",
      "304 torch.Size([64, 3, 32, 32])\n",
      "305 torch.Size([64, 3, 32, 32])\n",
      "306 torch.Size([64, 3, 32, 32])\n",
      "307 torch.Size([64, 3, 32, 32])\n",
      "308 torch.Size([64, 3, 32, 32])\n",
      "309 torch.Size([64, 3, 32, 32])\n",
      "310 torch.Size([64, 3, 32, 32])\n",
      "311 torch.Size([64, 3, 32, 32])\n",
      "312 torch.Size([64, 3, 32, 32])\n",
      "313 torch.Size([64, 3, 32, 32])\n",
      "314 torch.Size([64, 3, 32, 32])\n",
      "315 torch.Size([64, 3, 32, 32])\n",
      "316 torch.Size([64, 3, 32, 32])\n",
      "317 torch.Size([64, 3, 32, 32])\n",
      "318 torch.Size([64, 3, 32, 32])\n",
      "319 torch.Size([64, 3, 32, 32])\n",
      "320 torch.Size([64, 3, 32, 32])\n",
      "321 torch.Size([64, 3, 32, 32])\n",
      "322 torch.Size([64, 3, 32, 32])\n",
      "323 torch.Size([64, 3, 32, 32])\n",
      "324 torch.Size([64, 3, 32, 32])\n",
      "325 torch.Size([64, 3, 32, 32])\n",
      "326 torch.Size([64, 3, 32, 32])\n",
      "327 torch.Size([64, 3, 32, 32])\n",
      "328 torch.Size([64, 3, 32, 32])\n",
      "329 torch.Size([64, 3, 32, 32])\n",
      "330 torch.Size([64, 3, 32, 32])\n",
      "331 torch.Size([64, 3, 32, 32])\n",
      "332 torch.Size([64, 3, 32, 32])\n",
      "333 torch.Size([64, 3, 32, 32])\n",
      "334 torch.Size([64, 3, 32, 32])\n",
      "335 torch.Size([64, 3, 32, 32])\n",
      "336 torch.Size([64, 3, 32, 32])\n",
      "337 torch.Size([64, 3, 32, 32])\n",
      "338 torch.Size([64, 3, 32, 32])\n",
      "339 torch.Size([64, 3, 32, 32])\n",
      "340 torch.Size([64, 3, 32, 32])\n",
      "341 torch.Size([64, 3, 32, 32])\n",
      "342 torch.Size([64, 3, 32, 32])\n",
      "343 torch.Size([64, 3, 32, 32])\n",
      "344 torch.Size([64, 3, 32, 32])\n",
      "345 torch.Size([64, 3, 32, 32])\n",
      "346 torch.Size([64, 3, 32, 32])\n",
      "347 torch.Size([64, 3, 32, 32])\n",
      "348 torch.Size([64, 3, 32, 32])\n",
      "349 torch.Size([64, 3, 32, 32])\n",
      "350 torch.Size([64, 3, 32, 32])\n",
      "351 torch.Size([64, 3, 32, 32])\n",
      "352 torch.Size([64, 3, 32, 32])\n",
      "353 torch.Size([64, 3, 32, 32])\n",
      "354 torch.Size([64, 3, 32, 32])\n",
      "355 torch.Size([64, 3, 32, 32])\n",
      "356 torch.Size([64, 3, 32, 32])\n",
      "357 torch.Size([64, 3, 32, 32])\n",
      "358 torch.Size([64, 3, 32, 32])\n",
      "359 torch.Size([64, 3, 32, 32])\n",
      "360 torch.Size([64, 3, 32, 32])\n",
      "361 torch.Size([64, 3, 32, 32])\n",
      "362 torch.Size([64, 3, 32, 32])\n",
      "363 torch.Size([64, 3, 32, 32])\n",
      "364 torch.Size([64, 3, 32, 32])\n",
      "365 torch.Size([64, 3, 32, 32])\n",
      "366 torch.Size([64, 3, 32, 32])\n",
      "367 torch.Size([64, 3, 32, 32])\n",
      "368 torch.Size([64, 3, 32, 32])\n",
      "369 torch.Size([64, 3, 32, 32])\n",
      "370 torch.Size([64, 3, 32, 32])\n",
      "371 torch.Size([64, 3, 32, 32])\n",
      "372 torch.Size([64, 3, 32, 32])\n",
      "373 torch.Size([64, 3, 32, 32])\n",
      "374 torch.Size([64, 3, 32, 32])\n",
      "375 torch.Size([64, 3, 32, 32])\n",
      "376 torch.Size([64, 3, 32, 32])\n",
      "377 torch.Size([64, 3, 32, 32])\n",
      "378 torch.Size([64, 3, 32, 32])\n",
      "379 torch.Size([64, 3, 32, 32])\n",
      "380 torch.Size([64, 3, 32, 32])\n",
      "381 torch.Size([64, 3, 32, 32])\n",
      "382 torch.Size([64, 3, 32, 32])\n",
      "383 torch.Size([64, 3, 32, 32])\n",
      "384 torch.Size([64, 3, 32, 32])\n",
      "385 torch.Size([64, 3, 32, 32])\n",
      "386 torch.Size([64, 3, 32, 32])\n",
      "387 torch.Size([64, 3, 32, 32])\n",
      "388 torch.Size([64, 3, 32, 32])\n",
      "389 torch.Size([64, 3, 32, 32])\n",
      "390 torch.Size([64, 3, 32, 32])\n",
      "391 torch.Size([64, 3, 32, 32])\n",
      "392 torch.Size([64, 3, 32, 32])\n",
      "393 torch.Size([64, 3, 32, 32])\n",
      "394 torch.Size([64, 3, 32, 32])\n",
      "395 torch.Size([64, 3, 32, 32])\n",
      "396 torch.Size([64, 3, 32, 32])\n",
      "397 torch.Size([64, 3, 32, 32])\n",
      "398 torch.Size([64, 3, 32, 32])\n",
      "399 torch.Size([64, 3, 32, 32])\n",
      "t = 400, loss = 1.1868\n",
      "400 torch.Size([64, 3, 32, 32])\n",
      "401 torch.Size([64, 3, 32, 32])\n",
      "402 torch.Size([64, 3, 32, 32])\n",
      "403 torch.Size([64, 3, 32, 32])\n",
      "404 torch.Size([64, 3, 32, 32])\n",
      "405 torch.Size([64, 3, 32, 32])\n",
      "406 torch.Size([64, 3, 32, 32])\n",
      "407 torch.Size([64, 3, 32, 32])\n",
      "408 torch.Size([64, 3, 32, 32])\n",
      "409 torch.Size([64, 3, 32, 32])\n",
      "410 torch.Size([64, 3, 32, 32])\n",
      "411 torch.Size([64, 3, 32, 32])\n",
      "412 torch.Size([64, 3, 32, 32])\n",
      "413 torch.Size([64, 3, 32, 32])\n",
      "414 torch.Size([64, 3, 32, 32])\n",
      "415 torch.Size([64, 3, 32, 32])\n",
      "416 torch.Size([64, 3, 32, 32])\n",
      "417 torch.Size([64, 3, 32, 32])\n",
      "418 torch.Size([64, 3, 32, 32])\n",
      "419 torch.Size([64, 3, 32, 32])\n",
      "420 torch.Size([64, 3, 32, 32])\n",
      "421 torch.Size([64, 3, 32, 32])\n",
      "422 torch.Size([64, 3, 32, 32])\n",
      "423 torch.Size([64, 3, 32, 32])\n",
      "424 torch.Size([64, 3, 32, 32])\n",
      "425 torch.Size([64, 3, 32, 32])\n",
      "426 torch.Size([64, 3, 32, 32])\n",
      "427 torch.Size([64, 3, 32, 32])\n",
      "428 torch.Size([64, 3, 32, 32])\n",
      "429 torch.Size([64, 3, 32, 32])\n",
      "430 torch.Size([64, 3, 32, 32])\n",
      "431 torch.Size([64, 3, 32, 32])\n",
      "432 torch.Size([64, 3, 32, 32])\n",
      "433 torch.Size([64, 3, 32, 32])\n",
      "434 torch.Size([64, 3, 32, 32])\n",
      "435 torch.Size([64, 3, 32, 32])\n",
      "436 torch.Size([64, 3, 32, 32])\n",
      "437 torch.Size([64, 3, 32, 32])\n",
      "438 torch.Size([64, 3, 32, 32])\n",
      "439 torch.Size([64, 3, 32, 32])\n",
      "440 torch.Size([64, 3, 32, 32])\n",
      "441 torch.Size([64, 3, 32, 32])\n",
      "442 torch.Size([64, 3, 32, 32])\n",
      "443 torch.Size([64, 3, 32, 32])\n",
      "444 torch.Size([64, 3, 32, 32])\n",
      "445 torch.Size([64, 3, 32, 32])\n",
      "446 torch.Size([64, 3, 32, 32])\n",
      "447 torch.Size([64, 3, 32, 32])\n",
      "448 torch.Size([64, 3, 32, 32])\n",
      "449 torch.Size([64, 3, 32, 32])\n",
      "450 torch.Size([64, 3, 32, 32])\n",
      "451 torch.Size([64, 3, 32, 32])\n",
      "452 torch.Size([64, 3, 32, 32])\n",
      "453 torch.Size([64, 3, 32, 32])\n",
      "454 torch.Size([64, 3, 32, 32])\n",
      "455 torch.Size([64, 3, 32, 32])\n",
      "456 torch.Size([64, 3, 32, 32])\n",
      "457 torch.Size([64, 3, 32, 32])\n",
      "458 torch.Size([64, 3, 32, 32])\n",
      "459 torch.Size([64, 3, 32, 32])\n",
      "460 torch.Size([64, 3, 32, 32])\n",
      "461 torch.Size([64, 3, 32, 32])\n",
      "462 torch.Size([64, 3, 32, 32])\n",
      "463 torch.Size([64, 3, 32, 32])\n",
      "464 torch.Size([64, 3, 32, 32])\n",
      "465 torch.Size([64, 3, 32, 32])\n",
      "466 torch.Size([64, 3, 32, 32])\n",
      "467 torch.Size([64, 3, 32, 32])\n",
      "468 torch.Size([64, 3, 32, 32])\n",
      "469 torch.Size([64, 3, 32, 32])\n",
      "470 torch.Size([64, 3, 32, 32])\n",
      "471 torch.Size([64, 3, 32, 32])\n",
      "472 torch.Size([64, 3, 32, 32])\n",
      "473 torch.Size([64, 3, 32, 32])\n",
      "474 torch.Size([64, 3, 32, 32])\n",
      "475 torch.Size([64, 3, 32, 32])\n",
      "476 torch.Size([64, 3, 32, 32])\n",
      "477 torch.Size([64, 3, 32, 32])\n",
      "478 torch.Size([64, 3, 32, 32])\n",
      "479 torch.Size([64, 3, 32, 32])\n",
      "480 torch.Size([64, 3, 32, 32])\n",
      "481 torch.Size([64, 3, 32, 32])\n",
      "482 torch.Size([64, 3, 32, 32])\n",
      "483 torch.Size([64, 3, 32, 32])\n",
      "484 torch.Size([64, 3, 32, 32])\n",
      "485 torch.Size([64, 3, 32, 32])\n",
      "486 torch.Size([64, 3, 32, 32])\n",
      "487 torch.Size([64, 3, 32, 32])\n",
      "488 torch.Size([64, 3, 32, 32])\n",
      "489 torch.Size([64, 3, 32, 32])\n",
      "490 torch.Size([64, 3, 32, 32])\n",
      "491 torch.Size([64, 3, 32, 32])\n",
      "492 torch.Size([64, 3, 32, 32])\n",
      "493 torch.Size([64, 3, 32, 32])\n",
      "494 torch.Size([64, 3, 32, 32])\n",
      "495 torch.Size([64, 3, 32, 32])\n",
      "496 torch.Size([64, 3, 32, 32])\n",
      "497 torch.Size([64, 3, 32, 32])\n",
      "498 torch.Size([64, 3, 32, 32])\n",
      "499 torch.Size([64, 3, 32, 32])\n",
      "t = 500, loss = 1.1294\n",
      "500 torch.Size([64, 3, 32, 32])\n",
      "501 torch.Size([64, 3, 32, 32])\n",
      "502 torch.Size([64, 3, 32, 32])\n",
      "503 torch.Size([64, 3, 32, 32])\n",
      "504 torch.Size([64, 3, 32, 32])\n",
      "505 torch.Size([64, 3, 32, 32])\n",
      "506 torch.Size([64, 3, 32, 32])\n",
      "507 torch.Size([64, 3, 32, 32])\n",
      "508 torch.Size([64, 3, 32, 32])\n",
      "509 torch.Size([64, 3, 32, 32])\n",
      "510 torch.Size([64, 3, 32, 32])\n",
      "511 torch.Size([64, 3, 32, 32])\n",
      "512 torch.Size([64, 3, 32, 32])\n",
      "513 torch.Size([64, 3, 32, 32])\n",
      "514 torch.Size([64, 3, 32, 32])\n",
      "515 torch.Size([64, 3, 32, 32])\n",
      "516 torch.Size([64, 3, 32, 32])\n",
      "517 torch.Size([64, 3, 32, 32])\n",
      "518 torch.Size([64, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519 torch.Size([64, 3, 32, 32])\n",
      "520 torch.Size([64, 3, 32, 32])\n",
      "521 torch.Size([64, 3, 32, 32])\n",
      "522 torch.Size([64, 3, 32, 32])\n",
      "523 torch.Size([64, 3, 32, 32])\n",
      "524 torch.Size([64, 3, 32, 32])\n",
      "525 torch.Size([64, 3, 32, 32])\n",
      "526 torch.Size([64, 3, 32, 32])\n",
      "527 torch.Size([64, 3, 32, 32])\n",
      "528 torch.Size([64, 3, 32, 32])\n",
      "529 torch.Size([64, 3, 32, 32])\n",
      "530 torch.Size([64, 3, 32, 32])\n",
      "531 torch.Size([64, 3, 32, 32])\n",
      "532 torch.Size([64, 3, 32, 32])\n",
      "533 torch.Size([64, 3, 32, 32])\n",
      "534 torch.Size([64, 3, 32, 32])\n",
      "535 torch.Size([64, 3, 32, 32])\n",
      "536 torch.Size([64, 3, 32, 32])\n",
      "537 torch.Size([64, 3, 32, 32])\n",
      "538 torch.Size([64, 3, 32, 32])\n",
      "539 torch.Size([64, 3, 32, 32])\n",
      "540 torch.Size([64, 3, 32, 32])\n",
      "541 torch.Size([64, 3, 32, 32])\n",
      "542 torch.Size([64, 3, 32, 32])\n",
      "543 torch.Size([64, 3, 32, 32])\n",
      "544 torch.Size([64, 3, 32, 32])\n",
      "545 torch.Size([64, 3, 32, 32])\n",
      "546 torch.Size([64, 3, 32, 32])\n",
      "547 torch.Size([64, 3, 32, 32])\n",
      "548 torch.Size([64, 3, 32, 32])\n",
      "549 torch.Size([64, 3, 32, 32])\n",
      "550 torch.Size([64, 3, 32, 32])\n",
      "551 torch.Size([64, 3, 32, 32])\n",
      "552 torch.Size([64, 3, 32, 32])\n",
      "553 torch.Size([64, 3, 32, 32])\n",
      "554 torch.Size([64, 3, 32, 32])\n",
      "555 torch.Size([64, 3, 32, 32])\n",
      "556 torch.Size([64, 3, 32, 32])\n",
      "557 torch.Size([64, 3, 32, 32])\n",
      "558 torch.Size([64, 3, 32, 32])\n",
      "559 torch.Size([64, 3, 32, 32])\n",
      "560 torch.Size([64, 3, 32, 32])\n",
      "561 torch.Size([64, 3, 32, 32])\n",
      "562 torch.Size([64, 3, 32, 32])\n",
      "563 torch.Size([64, 3, 32, 32])\n",
      "564 torch.Size([64, 3, 32, 32])\n",
      "565 torch.Size([64, 3, 32, 32])\n",
      "566 torch.Size([64, 3, 32, 32])\n",
      "567 torch.Size([64, 3, 32, 32])\n",
      "568 torch.Size([64, 3, 32, 32])\n",
      "569 torch.Size([64, 3, 32, 32])\n",
      "570 torch.Size([64, 3, 32, 32])\n",
      "571 torch.Size([64, 3, 32, 32])\n",
      "572 torch.Size([64, 3, 32, 32])\n",
      "573 torch.Size([64, 3, 32, 32])\n",
      "574 torch.Size([64, 3, 32, 32])\n",
      "575 torch.Size([64, 3, 32, 32])\n",
      "576 torch.Size([64, 3, 32, 32])\n",
      "577 torch.Size([64, 3, 32, 32])\n",
      "578 torch.Size([64, 3, 32, 32])\n",
      "579 torch.Size([64, 3, 32, 32])\n",
      "580 torch.Size([64, 3, 32, 32])\n",
      "581 torch.Size([64, 3, 32, 32])\n",
      "582 torch.Size([64, 3, 32, 32])\n",
      "583 torch.Size([64, 3, 32, 32])\n",
      "584 torch.Size([64, 3, 32, 32])\n",
      "585 torch.Size([64, 3, 32, 32])\n",
      "586 torch.Size([64, 3, 32, 32])\n",
      "587 torch.Size([64, 3, 32, 32])\n",
      "588 torch.Size([64, 3, 32, 32])\n",
      "589 torch.Size([64, 3, 32, 32])\n",
      "590 torch.Size([64, 3, 32, 32])\n",
      "591 torch.Size([64, 3, 32, 32])\n",
      "592 torch.Size([64, 3, 32, 32])\n",
      "593 torch.Size([64, 3, 32, 32])\n",
      "594 torch.Size([64, 3, 32, 32])\n",
      "595 torch.Size([64, 3, 32, 32])\n",
      "596 torch.Size([64, 3, 32, 32])\n",
      "597 torch.Size([64, 3, 32, 32])\n",
      "598 torch.Size([64, 3, 32, 32])\n",
      "599 torch.Size([64, 3, 32, 32])\n",
      "t = 600, loss = 1.2845\n",
      "600 torch.Size([64, 3, 32, 32])\n",
      "601 torch.Size([64, 3, 32, 32])\n",
      "602 torch.Size([64, 3, 32, 32])\n",
      "603 torch.Size([64, 3, 32, 32])\n",
      "604 torch.Size([64, 3, 32, 32])\n",
      "605 torch.Size([64, 3, 32, 32])\n",
      "606 torch.Size([64, 3, 32, 32])\n",
      "607 torch.Size([64, 3, 32, 32])\n",
      "608 torch.Size([64, 3, 32, 32])\n",
      "609 torch.Size([64, 3, 32, 32])\n",
      "610 torch.Size([64, 3, 32, 32])\n",
      "611 torch.Size([64, 3, 32, 32])\n",
      "612 torch.Size([64, 3, 32, 32])\n",
      "613 torch.Size([64, 3, 32, 32])\n",
      "614 torch.Size([64, 3, 32, 32])\n",
      "615 torch.Size([64, 3, 32, 32])\n",
      "616 torch.Size([64, 3, 32, 32])\n",
      "617 torch.Size([64, 3, 32, 32])\n",
      "618 torch.Size([64, 3, 32, 32])\n",
      "619 torch.Size([64, 3, 32, 32])\n",
      "620 torch.Size([64, 3, 32, 32])\n",
      "621 torch.Size([64, 3, 32, 32])\n",
      "622 torch.Size([64, 3, 32, 32])\n",
      "623 torch.Size([64, 3, 32, 32])\n",
      "624 torch.Size([64, 3, 32, 32])\n",
      "625 torch.Size([64, 3, 32, 32])\n",
      "626 torch.Size([64, 3, 32, 32])\n",
      "627 torch.Size([64, 3, 32, 32])\n",
      "628 torch.Size([64, 3, 32, 32])\n",
      "629 torch.Size([64, 3, 32, 32])\n",
      "630 torch.Size([64, 3, 32, 32])\n",
      "631 torch.Size([64, 3, 32, 32])\n",
      "632 torch.Size([64, 3, 32, 32])\n",
      "633 torch.Size([64, 3, 32, 32])\n",
      "634 torch.Size([64, 3, 32, 32])\n",
      "635 torch.Size([64, 3, 32, 32])\n",
      "636 torch.Size([64, 3, 32, 32])\n",
      "637 torch.Size([64, 3, 32, 32])\n",
      "638 torch.Size([64, 3, 32, 32])\n",
      "639 torch.Size([64, 3, 32, 32])\n",
      "640 torch.Size([64, 3, 32, 32])\n",
      "641 torch.Size([64, 3, 32, 32])\n",
      "642 torch.Size([64, 3, 32, 32])\n",
      "643 torch.Size([64, 3, 32, 32])\n",
      "644 torch.Size([64, 3, 32, 32])\n",
      "645 torch.Size([64, 3, 32, 32])\n",
      "646 torch.Size([64, 3, 32, 32])\n",
      "647 torch.Size([64, 3, 32, 32])\n",
      "648 torch.Size([64, 3, 32, 32])\n",
      "649 torch.Size([64, 3, 32, 32])\n",
      "650 torch.Size([64, 3, 32, 32])\n",
      "651 torch.Size([64, 3, 32, 32])\n",
      "652 torch.Size([64, 3, 32, 32])\n",
      "653 torch.Size([64, 3, 32, 32])\n",
      "654 torch.Size([64, 3, 32, 32])\n",
      "655 torch.Size([64, 3, 32, 32])\n",
      "656 torch.Size([64, 3, 32, 32])\n",
      "657 torch.Size([64, 3, 32, 32])\n",
      "658 torch.Size([64, 3, 32, 32])\n",
      "659 torch.Size([64, 3, 32, 32])\n",
      "660 torch.Size([64, 3, 32, 32])\n",
      "661 torch.Size([64, 3, 32, 32])\n",
      "662 torch.Size([64, 3, 32, 32])\n",
      "663 torch.Size([64, 3, 32, 32])\n",
      "664 torch.Size([64, 3, 32, 32])\n",
      "665 torch.Size([64, 3, 32, 32])\n",
      "666 torch.Size([64, 3, 32, 32])\n",
      "667 torch.Size([64, 3, 32, 32])\n",
      "668 torch.Size([64, 3, 32, 32])\n",
      "669 torch.Size([64, 3, 32, 32])\n",
      "670 torch.Size([64, 3, 32, 32])\n",
      "671 torch.Size([64, 3, 32, 32])\n",
      "672 torch.Size([64, 3, 32, 32])\n",
      "673 torch.Size([64, 3, 32, 32])\n",
      "674 torch.Size([64, 3, 32, 32])\n",
      "675 torch.Size([64, 3, 32, 32])\n",
      "676 torch.Size([64, 3, 32, 32])\n",
      "677 torch.Size([64, 3, 32, 32])\n",
      "678 torch.Size([64, 3, 32, 32])\n",
      "679 torch.Size([64, 3, 32, 32])\n",
      "680 torch.Size([64, 3, 32, 32])\n",
      "681 torch.Size([64, 3, 32, 32])\n",
      "682 torch.Size([64, 3, 32, 32])\n",
      "683 torch.Size([64, 3, 32, 32])\n",
      "684 torch.Size([64, 3, 32, 32])\n",
      "685 torch.Size([64, 3, 32, 32])\n",
      "686 torch.Size([64, 3, 32, 32])\n",
      "687 torch.Size([64, 3, 32, 32])\n",
      "688 torch.Size([64, 3, 32, 32])\n",
      "689 torch.Size([64, 3, 32, 32])\n",
      "690 torch.Size([64, 3, 32, 32])\n",
      "691 torch.Size([64, 3, 32, 32])\n",
      "692 torch.Size([64, 3, 32, 32])\n",
      "693 torch.Size([64, 3, 32, 32])\n",
      "694 torch.Size([64, 3, 32, 32])\n",
      "695 torch.Size([64, 3, 32, 32])\n",
      "696 torch.Size([64, 3, 32, 32])\n",
      "697 torch.Size([64, 3, 32, 32])\n",
      "698 torch.Size([64, 3, 32, 32])\n",
      "699 torch.Size([64, 3, 32, 32])\n",
      "t = 700, loss = 1.5045\n",
      "700 torch.Size([64, 3, 32, 32])\n",
      "701 torch.Size([64, 3, 32, 32])\n",
      "702 torch.Size([64, 3, 32, 32])\n",
      "703 torch.Size([64, 3, 32, 32])\n",
      "704 torch.Size([64, 3, 32, 32])\n",
      "705 torch.Size([64, 3, 32, 32])\n",
      "706 torch.Size([64, 3, 32, 32])\n",
      "707 torch.Size([64, 3, 32, 32])\n",
      "708 torch.Size([64, 3, 32, 32])\n",
      "709 torch.Size([64, 3, 32, 32])\n",
      "710 torch.Size([64, 3, 32, 32])\n",
      "711 torch.Size([64, 3, 32, 32])\n",
      "712 torch.Size([64, 3, 32, 32])\n",
      "713 torch.Size([64, 3, 32, 32])\n",
      "714 torch.Size([64, 3, 32, 32])\n",
      "715 torch.Size([64, 3, 32, 32])\n",
      "716 torch.Size([64, 3, 32, 32])\n",
      "717 torch.Size([64, 3, 32, 32])\n",
      "718 torch.Size([64, 3, 32, 32])\n",
      "719 torch.Size([64, 3, 32, 32])\n",
      "720 torch.Size([64, 3, 32, 32])\n",
      "721 torch.Size([64, 3, 32, 32])\n",
      "722 torch.Size([64, 3, 32, 32])\n",
      "723 torch.Size([64, 3, 32, 32])\n",
      "724 torch.Size([64, 3, 32, 32])\n",
      "725 torch.Size([64, 3, 32, 32])\n",
      "726 torch.Size([64, 3, 32, 32])\n",
      "727 torch.Size([64, 3, 32, 32])\n",
      "728 torch.Size([64, 3, 32, 32])\n",
      "729 torch.Size([64, 3, 32, 32])\n",
      "730 torch.Size([64, 3, 32, 32])\n",
      "731 torch.Size([64, 3, 32, 32])\n",
      "732 torch.Size([64, 3, 32, 32])\n",
      "733 torch.Size([64, 3, 32, 32])\n",
      "734 torch.Size([64, 3, 32, 32])\n",
      "735 torch.Size([64, 3, 32, 32])\n",
      "736 torch.Size([64, 3, 32, 32])\n",
      "737 torch.Size([64, 3, 32, 32])\n",
      "738 torch.Size([64, 3, 32, 32])\n",
      "739 torch.Size([64, 3, 32, 32])\n",
      "740 torch.Size([64, 3, 32, 32])\n",
      "741 torch.Size([64, 3, 32, 32])\n",
      "742 torch.Size([64, 3, 32, 32])\n",
      "743 torch.Size([64, 3, 32, 32])\n",
      "744 torch.Size([64, 3, 32, 32])\n",
      "745 torch.Size([64, 3, 32, 32])\n",
      "746 torch.Size([64, 3, 32, 32])\n",
      "747 torch.Size([64, 3, 32, 32])\n",
      "748 torch.Size([64, 3, 32, 32])\n",
      "749 torch.Size([64, 3, 32, 32])\n",
      "750 torch.Size([64, 3, 32, 32])\n",
      "751 torch.Size([64, 3, 32, 32])\n",
      "752 torch.Size([64, 3, 32, 32])\n",
      "753 torch.Size([64, 3, 32, 32])\n",
      "754 torch.Size([64, 3, 32, 32])\n",
      "755 torch.Size([64, 3, 32, 32])\n",
      "756 torch.Size([64, 3, 32, 32])\n",
      "757 torch.Size([64, 3, 32, 32])\n",
      "758 torch.Size([64, 3, 32, 32])\n",
      "759 torch.Size([64, 3, 32, 32])\n",
      "760 torch.Size([64, 3, 32, 32])\n",
      "761 torch.Size([64, 3, 32, 32])\n",
      "762 torch.Size([64, 3, 32, 32])\n",
      "763 torch.Size([64, 3, 32, 32])\n",
      "764 torch.Size([64, 3, 32, 32])\n",
      "765 torch.Size([40, 3, 32, 32])\n",
      "Checking accuracy on validation set\n",
      "Got 547 / 1000 correct (54.70)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.random.manual_seed(12345)\n",
    "fixed_model_gpu.apply(reset)\n",
    "train(fixed_model_gpu, loss_fn, optimizer, num_epochs=1)\n",
    "check_accuracy(fixed_model_gpu, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget the validation set!\n",
    "\n",
    "And note that you can use the check_accuracy function to evaluate on either the test set or the validation set, by passing either **loader_test** or **loader_val** as the second argument to check_accuracy. You should not touch the test set until you have finished your architecture and hyperparameter tuning, and only run the test set once at the end to report a final value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a _great_ model on CIFAR-10!\n",
    "\n",
    "Now it's your job to experiment with architectures, hyperparameters, loss functions, and optimizers to train a model that achieves **>=70%** accuracy on the CIFAR-10 **validation** set. You can use the check_accuracy and train functions from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things you should try:\n",
    "- **Filter size**: Above we used 7x7; this makes pretty pictures but smaller filters may be more efficient\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and regularization strength. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these; however they would be good things to try for extra credit.\n",
    "\n",
    "- Alternative update steps: For the assignment we implemented SGD+momentum, RMSprop, and Adam; you could try alternatives like AdaGrad or AdaDelta.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "If you do decide to implement something extra, clearly describe it in the \"Extra Credit Description\" cell below.\n",
    "\n",
    "### What we expect\n",
    "At the very least, you should be able to train a ConvNet that gets at least 70% accuracy on the validation set. This is just a lower bound - if you are careful it should be possible to get accuracies much higher than that! Extra credit points will be awarded for particularly high-scoring models or unique approaches.\n",
    "\n",
    "You should use the space below to experiment and train your network. \n",
    "\n",
    "Have fun and happy training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "is_same_size received an invalid combination of arguments - got (\u001b[31;1mtorch.cuda.FloatTensor\u001b[0m), but expected (torch.cuda.LongTensor other)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cde3b311d5ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-216af6c4903a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't = %d, loss = %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultilabel_soft_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmultilabel_soft_margin_loss\u001b[0;34m(input, target, weight, size_average)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultilabel_soft_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average)\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \"\"\"\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_same_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         warnings.warn(\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\n\u001b[1;32m    767\u001b[0m                       \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mis_same_size\u001b[0;34m(self, other_var)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_same_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_same_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: is_same_size received an invalid combination of arguments - got (\u001b[31;1mtorch.cuda.FloatTensor\u001b[0m), but expected (torch.cuda.LongTensor other)"
     ]
    }
   ],
   "source": [
    "# Train your model here, and make sure the output of this cell is the accuracy of your best model on the \n",
    "# train, val, and test sets. Here's some code to get you started. The output of this cell should be the training\n",
    "# and validation accuracy on your best model (measured by validation accuracy).\n",
    "\n",
    "model = None\n",
    "loss_fn = None\n",
    "optimizer = None\n",
    "\n",
    "model = nn.Sequential( # You fill this in!\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(64, affine=False),\n",
    "                nn.MaxPool2d(2, stride=2, dilation=1),\n",
    "                \n",
    "                nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(96, affine=False),\n",
    "                nn.MaxPool2d(2, stride=2, dilation=1),\n",
    "\n",
    "                nn.Conv2d(96, 128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(128, affine=False),\n",
    "                nn.MaxPool2d(2, stride=2, dilation=1),\n",
    "    \n",
    "                Flatten(), # see above for explanation\n",
    "                nn.Linear(2048, 1024), # affine layer\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(1024, 1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(1024,10),\n",
    "\n",
    "            )\n",
    "model_gpu = copy.deepcopy(model).type(gpu_dtype)\n",
    "#torch.cuda.random.manual_seed(12345)\n",
    "#model_gpu.apply(reset)\n",
    "loss_fn = nn.MultiLabelSoftMarginLoss().type(gpu_dtype)\n",
    "optimizer = optim.Adam(model_gpu.parameters(), lr=0.001)\n",
    "\n",
    "train(model_gpu, loss_fn, optimizer, num_epochs=1)\n",
    "check_accuracy(model_gpu, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/shang/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m(309)\u001b[0;36mis_same_size\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    307 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    308 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mis_same_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 309 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_same_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    310 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    311 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self.data.size()\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe what you did \n",
    "\n",
    "In the cell below you should write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell us here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set -- run this only once\n",
    "\n",
    "Now that we've gotten a result we're happy with, we test our final model on the test set (which you should store in best_model).  This would be the score we would achieve on a competition. Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "check_accuracy(best_model, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further with PyTorch\n",
    "\n",
    "The next assignment will make heavy use of PyTorch. You might also find it useful for your projects. \n",
    "\n",
    "Here's a nice tutorial by Justin Johnson that shows off some of PyTorch's features, like dynamic graphs and custom NN modules: http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "\n",
    "If you're interested in reinforcement learning for your final project, this is a good (more advanced) DQN tutorial in PyTorch: http://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
